# Evaluating Explanatory Capabilities of Large Language Models
This repository acts as a codebase for my COMP0091 MSc Machine Learning Project at UCL

Link to the thesis: https://drive.google.com/file/d/1tjavJl-6f5vK5b-xba_hUyjCtoPrSB-a/view?usp=sharing

## Instructions to run the models:
For closed source models, get the API key and run the file "gpt_sample.py" (Add API key as well). 
It is currently for esnli. Change it to sbic or ecqa based on llama code file changes.

For open-source replicate models, get the api key or weights and run the "replicate_sample_code.py" with appropriate changes

For LLaMA, get the weights of the model and run the LLaMA files in the Code folder.

The prompts are given in the prompts folder

## Computing the scores

Run the ipynb jupyter notebooks with appropriate file name changes in the fileio processing steps. 

Any issues in running the code, contact me at vvssmounik@gmail.com


